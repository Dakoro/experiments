{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an implementation of Self-Compressing Neural Networks\n",
    "# https://arxiv.org/pdf/2301.13142\n",
    "import os\n",
    "import tqdm\n",
    "#os.environ[\"DEBUG\"] = '2'\n",
    "#os.environ[\"JITBEAM\"] = '2'   # make tinygrad fast, first run is slow but then it's fast\n",
    "from tinygrad.nn.datasets import mnist\n",
    "X_train, Y_train, X_test, Y_test = mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import Tensor, nn, TinyJit, dtypes\n",
    "from tinygrad.helpers import prod\n",
    "import math, functools\n",
    "\n",
    "class QConv2d:\n",
    "  def __init__(self, in_channels, out_channels, kernel_size):\n",
    "    self.kernel_size = (kernel_size, kernel_size) if isinstance(kernel_size, int) else tuple(kernel_size)\n",
    "    scale = 1 / math.sqrt(in_channels * prod(self.kernel_size))\n",
    "    self.weight = Tensor.uniform(out_channels, in_channels, *self.kernel_size, low=-scale, high=scale)\n",
    "    self.e = Tensor.full((out_channels, 1, 1, 1), -8.)\n",
    "    self.b = Tensor.full((out_channels, 1, 1, 1), 2.)  # start with 2 bits per weight\n",
    "\n",
    "  def qbits(self):\n",
    "    return self.b.relu().sum() * prod(self.weight.shape[1:])\n",
    "\n",
    "  def qweight(self):\n",
    "        return Tensor.minimum(Tensor.maximum(2**-self.e * self.weight, -2**(self.b.relu()-1)), 2**(self.b.relu()-1) - 1)\n",
    "  \n",
    "  def __call__(self, x:Tensor):\n",
    "    qw = self.qweight()\n",
    "    print(self.weight.shape)\n",
    "    print(qw.shape)\n",
    "    w = (qw.round() - qw).detach() + qw  # straight through estimator\n",
    "    print((2**self.e * w).shape)\n",
    "    return x.conv2d(2**self.e * w)\n",
    "\n",
    "class Model:\n",
    "  def __init__(self):\n",
    "    self.layers: List[Callable[[Tensor], Tensor]] = [ \n",
    "      QConv2d(1, 32, 5), Tensor.relu,\n",
    "      QConv2d(32, 32, 5), Tensor.relu,\n",
    "      nn.BatchNorm(32, affine=False, track_running_stats=False),\n",
    "      Tensor.max_pool2d,\n",
    "      QConv2d(32, 64, 3), Tensor.relu,\n",
    "      QConv2d(64, 64, 3), Tensor.relu,\n",
    "      nn.BatchNorm(64, affine=False, track_running_stats=False), \n",
    "      Tensor.max_pool2d,\n",
    "      # TODO: do we really need this reshape?\n",
    "      lambda x: x.flatten(1).reshape(-1, 576, 1, 1),\n",
    "      QConv2d(576, 10, 1), lambda x: x.flatten(1)]\n",
    "\n",
    "  def __call__(self, x:Tensor) -> Tensor:\n",
    "      return x.sequential(self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tinygrad.nn' has no attribute 'BatchNorm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m opt \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(nn\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mget_parameters(model))\n\u001b[1;32m      3\u001b[0m test_accs, bytes_used \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     29\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers: List[Callable[[Tensor], Tensor]] \u001b[38;5;241m=\u001b[39m [ \n\u001b[1;32m     30\u001b[0m     QConv2d(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m5\u001b[39m), Tensor\u001b[38;5;241m.\u001b[39mrelu,\n\u001b[1;32m     31\u001b[0m     QConv2d(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m5\u001b[39m), Tensor\u001b[38;5;241m.\u001b[39mrelu,\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNorm\u001b[49m(\u001b[38;5;241m32\u001b[39m, affine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, track_running_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     33\u001b[0m     Tensor\u001b[38;5;241m.\u001b[39mmax_pool2d,\n\u001b[1;32m     34\u001b[0m     QConv2d(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m), Tensor\u001b[38;5;241m.\u001b[39mrelu,\n\u001b[1;32m     35\u001b[0m     QConv2d(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m), Tensor\u001b[38;5;241m.\u001b[39mrelu,\n\u001b[1;32m     36\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm(\u001b[38;5;241m64\u001b[39m, affine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, track_running_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \n\u001b[1;32m     37\u001b[0m     Tensor\u001b[38;5;241m.\u001b[39mmax_pool2d,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# TODO: do we really need this reshape?\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m576\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     40\u001b[0m     QConv2d(\u001b[38;5;241m576\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m)]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tinygrad.nn' has no attribute 'BatchNorm'"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "opt = nn.optim.Adam(nn.state.get_parameters(model))\n",
    "test_accs, bytes_used = [], []\n",
    "weight_count = sum(t.numel() for t in opt.params)\n",
    "len(opt.params), weight_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 5, 5)\n",
      "(32, 1, 5, 5)\n",
      "(32, 1, 5, 5)\n",
      "(32, 32, 5, 5)\n",
      "(32, 32, 5, 5)\n",
      "(32, 32, 5, 5)\n",
      "(64, 32, 3, 3)\n",
      "(64, 32, 3, 3)\n",
      "(64, 32, 3, 3)\n",
      "(64, 64, 3, 3)\n",
      "(64, 64, 3, 3)\n",
      "(64, 64, 3, 3)\n",
      "(10, 576, 1, 1)\n",
      "(10, 576, 1, 1)\n",
      "(10, 576, 1, 1)\n",
      "<Tensor <LB NV () float (<BinaryOps.ADD: 1>, None)> on NV with grad <LB NV () float (<MetaOps.CONST: 2>, None)>> <Tensor <LB NV () float (<MetaOps.CONST: 2>, None)> on NV with grad <LB NV () float (<MetaOps.CONST: 2>, None)>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "wait_result: 10000 ms TIMEOUT!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m loss, Q \u001b[38;5;241m=\u001b[39m train_step()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss, Q)\n\u001b[0;32m---> 19\u001b[0m model_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m*\u001b[39mweight_count\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_bytes)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m9\u001b[39m:\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/tensor.py:3161\u001b[0m, in \u001b[0;36m_metadata_wrapper.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 3161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3163\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   3164\u001b[0m     caller_frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe(frame \u001b[38;5;241m:=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/tensor.py:274\u001b[0m, in \u001b[0;36mTensor.item\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfmt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno fmt dtype for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust have one element for item\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfmt)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/tensor.py:3161\u001b[0m, in \u001b[0;36m_metadata_wrapper.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 3161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3163\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   3164\u001b[0m     caller_frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe(frame \u001b[38;5;241m:=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/tensor.py:245\u001b[0m, in \u001b[0;36mTensor._data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(\u001b[38;5;28mbytearray\u001b[39m(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# NOTE: this realizes on the object from as_buffer being a Python object\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m cpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCLANG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m buf \u001b[38;5;241m=\u001b[39m cast(Buffer, cast(LazyBuffer, cpu\u001b[38;5;241m.\u001b[39mlazydata)\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mrealized)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLANG\u001b[39m\u001b[38;5;124m\"\u001b[39m: buf\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m BufferOptions(nolru\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/tensor.py:3161\u001b[0m, in \u001b[0;36m_metadata_wrapper.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 3161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3163\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   3164\u001b[0m     caller_frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe(frame \u001b[38;5;241m:=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/tensor.py:204\u001b[0m, in \u001b[0;36mTensor.realize\u001b[0;34m(self, do_update_stats, *lst)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrealize\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mlst:Tensor, do_update_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Triggers the computation needed to create these Tensor(s).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m   \u001b[43mrun_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_with_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlst\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_update_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_update_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/engine/realize.py:219\u001b[0m, in \u001b[0;36mrun_schedule\u001b[0;34m(schedule, var_vals, do_update_stats)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_schedule\u001b[39m(schedule:List[ScheduleItem], var_vals:Optional[Dict[Variable, \u001b[38;5;28mint\u001b[39m]]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, do_update_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 219\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m ei \u001b[38;5;129;01min\u001b[39;00m lower_schedule(schedule):\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(capturing) \u001b[38;5;129;01mand\u001b[39;00m CAPTURING: capturing[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39madd(ei)\n\u001b[1;32m    221\u001b[0m     ei\u001b[38;5;241m.\u001b[39mrun(var_vals, do_update_stats\u001b[38;5;241m=\u001b[39mdo_update_stats)\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/engine/realize.py:212\u001b[0m, in \u001b[0;36mlower_schedule\u001b[0;34m(schedule)\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor operations:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m   pprint\u001b[38;5;241m.\u001b[39mpprint(si\u001b[38;5;241m.\u001b[39mmetadata, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/engine/realize.py:206\u001b[0m, in \u001b[0;36mlower_schedule\u001b[0;34m(schedule)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(schedule):\n\u001b[1;32m    205\u001b[0m   si \u001b[38;5;241m=\u001b[39m schedule\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mlower_schedule_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43msi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/engine/realize.py:190\u001b[0m, in \u001b[0;36mlower_schedule_item\u001b[0;34m(si)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(x\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m si\u001b[38;5;241m.\u001b[39mbufs)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m si\u001b[38;5;241m.\u001b[39mast\u001b[38;5;241m.\u001b[39mop \u001b[38;5;129;01mis\u001b[39;00m MetaOps\u001b[38;5;241m.\u001b[39mCOPY \u001b[38;5;129;01mor\u001b[39;00m getenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_COPY_KERNEL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m si\u001b[38;5;241m.\u001b[39mast\u001b[38;5;241m.\u001b[39mop \u001b[38;5;129;01mis\u001b[39;00m MetaOps\u001b[38;5;241m.\u001b[39mKERNEL:\n\u001b[0;32m--> 190\u001b[0m   runner \u001b[38;5;241m=\u001b[39m \u001b[43mget_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43msi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ExecItem(runner, [si\u001b[38;5;241m.\u001b[39mbufs[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mp\u001b[38;5;241m.\u001b[39mglobals], si\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[1;32m    192\u001b[0m out \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/engine/realize.py:160\u001b[0m, in \u001b[0;36mget_runner\u001b[0;34m(dname, ast)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuzz_uops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UOpsFuzzerRunner\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UOpsFuzzerRunner(replace(prg, dname\u001b[38;5;241m=\u001b[39mdname))\n\u001b[0;32m--> 160\u001b[0m   method_cache[ckey] \u001b[38;5;241m=\u001b[39m method_cache[bkey] \u001b[38;5;241m=\u001b[39m ret \u001b[38;5;241m=\u001b[39m \u001b[43mCompiledRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/engine/realize.py:83\u001b[0m, in \u001b[0;36mCompiledRunner.__init__\u001b[0;34m(self, p, precompiled)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp:Program \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlib:\u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m precompiled \u001b[38;5;28;01mif\u001b[39;00m precompiled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m Device[p\u001b[38;5;241m.\u001b[39mdname]\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mcompile_cached(p\u001b[38;5;241m.\u001b[39msrc)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclprg \u001b[38;5;241m=\u001b[39m \u001b[43mDevice\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruntime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(p\u001b[38;5;241m.\u001b[39mname, p\u001b[38;5;241m.\u001b[39mdname, p\u001b[38;5;241m.\u001b[39mop_estimate, p\u001b[38;5;241m.\u001b[39mmem_estimate, p\u001b[38;5;241m.\u001b[39mlds_estimate)\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/runtime/ops_nv.py:231\u001b[0m, in \u001b[0;36mNVProgram.__init__\u001b[0;34m(self, device, name, lib)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m off \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, sh\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39msh_size, \u001b[38;5;241m12\u001b[39m):\n\u001b[1;32m    230\u001b[0m       typ, _, val \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack_from(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIII\u001b[39m\u001b[38;5;124m\"\u001b[39m, sh\u001b[38;5;241m.\u001b[39mcontent, off)\n\u001b[0;32m--> 231\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xffff\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0x1204\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_has_local_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x240\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Apply relocs\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m apply_image_offset, rel_sym_offset, typ, _ \u001b[38;5;129;01min\u001b[39;00m relocs:\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;66;03m# These types are CUDA-specific, applying them here\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/runtime/ops_nv.py:523\u001b[0m, in \u001b[0;36mNVDevice._ensure_has_local_memory\u001b[0;34m(self, required)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_has_local_memory\u001b[39m(\u001b[38;5;28mself\u001b[39m, required):\n\u001b[1;32m    521\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslm_per_thread \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m required: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshader_local_mem\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gpu_free(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshader_local_mem) \u001b[38;5;66;03m# type: ignore # pylint: disable=access-member-before-definition\u001b[39;00m\n\u001b[1;32m    526\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslm_per_thread \u001b[38;5;241m=\u001b[39m round_up(required, \u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/device.py:506\u001b[0m, in \u001b[0;36mHCQCompiled.synchronize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msynchronize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 506\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeline_signal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeline_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeline_value \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m31\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_timeline_signal()\n\u001b[1;32m    509\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m PROFILE:\n",
      "File \u001b[0;32m~/.virtualenvs/experiment/lib/python3.10/site-packages/tinygrad/runtime/ops_nv.py:80\u001b[0m, in \u001b[0;36mNVSignal.wait\u001b[0;34m(self, value, timeout)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m<\u001b[39m timeout:\n\u001b[1;32m     79\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m value: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ms TIMEOUT!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: wait_result: 10000 ms TIMEOUT!"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_step() -> Tensor:\n",
    "  with Tensor.train():\n",
    "    samples = Tensor.randint(512, high=X_train.shape[0])\n",
    "    loss = model(X_train[samples]).sparse_categorical_crossentropy(Y_train[samples])\n",
    "    Q = functools.reduce(lambda x,y: x+y, [l.qbits() for l in model.layers if isinstance(l, QConv2d)]) / weight_count\n",
    "    loss = loss + 0.05*Q  \n",
    "    loss.backward()\n",
    "  return loss, Q\n",
    "\n",
    "\n",
    "def get_test_acc() -> Tensor: return (model(X_test).argmax(axis=1) == Y_test).mean()*100\n",
    "\n",
    "Tensor.training = True\n",
    "from tqdm import trange\n",
    "test_acc = float('nan')\n",
    "for i in (t:=trange(20000)):\n",
    "  loss, Q = train_step()\n",
    "  print(loss, Q)\n",
    "  model_bytes = Q.item()/8*weight_count\n",
    "  print(model_bytes)\n",
    "  if i%10 == 9:\n",
    "    test_acc = get_test_acc().item()\n",
    "  test_accs.append(test_acc)\n",
    "  bytes_used.append(model_bytes)\n",
    "  t.set_description(f\"loss: {loss.item():6.2f}  bytes: {model_bytes:.1f}  acc: {test_acc:5.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
